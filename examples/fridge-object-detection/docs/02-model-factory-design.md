# Model Factory Design

This document provides an overview and detailed specifications for the design and implementation of a model factory. 

## Introduction

The model factory is a system that automates the end-to-end process of developing, training, deploying, and managing machine learning models. This document outlines the architecture, components, and workflow of the model factory, along with the necessary requirements and considerations.

## Features of Model Factory

- Supports generation of multiple ML Models.  
- MLOps pipeline for Data preparation, transformation, Model Training, evaluation, scoring and registration.  
- Each ML Model is packaged in an independent Docker Image.  
- Model verification before storing the Docker image.  
- All Docker images are stored in Azure Container Registry.  
- Builds and deploys Smoke Test module on Edge device.  
- Based on Azure ML SDK v2 1.4 and IoT Edge runtime 1.4.  

## Architecture

It consists of following components:

1. **Model Source**
   Model source contains the code written by data science team to execute the different stages of model development lifecycle. It is part of `src` folder in the model directory.
1. **Model Packaging**
   This component is used to package ML model into docker container images. It is part of `model` folder in model directory.
1. **MLOps Pipelines**
   It is a placeholder for different ml components used to create MLOps pipelines. It also contains ml ops pipelines code which can be triggered from DevOps pipelines. It is part of `mlops` folder in model directory.
1. **DevOps Pipelines**
   It contains Azure DevOps related pipelines which help in converting the ml code into model container images and push them to the container registry. It is part of `devops` folder in model directory. These pipelines perform various tasks like:  
   a. Validation of python code(linting, and unit testing)  
   b. Execution of MLOps pipelines and registering model on AML workspace.  
   c. Creation of model docker container images.  
   d. Pushing those docker container images to ACR.  
   e. Performing Smoke tests on those docker   container images.  
1. **Model Repository**
   Model Repository is part of AML workspace which store all the models generated by MLOps pipelines.
1. **Docker Container Repository**
   It stores all the model docker container images.
1. **Notebooks**
   These are Jupyter notebooks used by data science team to work and test logic of model generation. These are contained in `notebooks` folder in model_factory folder.
1. **Common Code**
   These are common code which consists of common DevOps template pipelines and also common code for MLOps. It is contained in `common` folder in model_factory directory.
1. **Unit Tests**
   These are specific to each model and are contained in `tests` folder in model directory.

## Development workflow of Model Factory  

![development flow](/docs/assets/images/model_factory_design.jpg)

The above diagram depicts the development workflow of model factory. At a high level following steps are followed in the workflow:

1. Data Science team works on development of model on local machine using VSCode remote extension or on AML workspace. This development is generally done in Jupyter notebook.
1. Once the model is ready and is tested, code from notebooks is brought into `src` folder for that model.
1. Code is then pushed to dev environment, where MLOps and DevOps pipelines are built and triggered which helps in automating the generation of ML models and pushing ML model docker containers images the dev ACR.
1. Data Science team validates the model metrics after which the code is push to prod env where pipelines execute basic tests and also perform smoke test on the IoTEdge device.
1. Once all steps are successful there is final Gated approval check which allows pushing of these images into prod ACR.

## Model Factory development sequence diagram

![branching strategy](/docs/assets/images/deployment_sequence_diagram.jpg)

The above diagram depicts the model factory sequence diagram. Here are the steps followed:

1. For each model a feature branch is created. This feature branch is protected by branch policies. Data scientist working on model, creates a user branch to perform local development, and creates a PR to the feature branch, which triggers PR validation pipeline.
1. PR merge to feature branch triggers CI pipelines which performs tasks like linting/unit testing. It also executes AML pipelines which train and register model, build docker images and pushes them to dev ACR. Multiple PR merges to feature branch can cause multiple execution on AML pipelines, which can incur more cost. Based on the workflow, we can optimize this step by using following approaches
    1. Reduce the size of training dataset.
    1. Set epoch number to 1 to limit the model training to loop through dataset only once.
    1. Run model training scheduled once in a day(nightly).
1. Once feature branch is validated and tested, user creates PR to main branch which performs more elaborate tasks like running smoke test on the smoke test edge device. After this, PR is merge to main branch. From main branch pipeline can be triggered manually, which pushes docker images to prod ACR.
